from fastapi import APIRouter, Query
from typing import List, Optional, Dict
from pydantic import BaseModel
import yfinance as yf
from datetime import datetime, timedelta
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import pytz

router = APIRouter()

# ë¯¸êµ­ ê³µíœ´ì¼ (2024-2025)
US_MARKET_HOLIDAYS = [
    "2024-01-01",  # New Year's Day
    "2024-01-15",  # Martin Luther King Jr. Day
    "2024-02-19",  # Presidents Day
    "2024-03-29",  # Good Friday
    "2024-05-27",  # Memorial Day
    "2024-06-19",  # Juneteenth
    "2024-07-04",  # Independence Day
    "2024-09-02",  # Labor Day
    "2024-11-28",  # Thanksgiving
    "2024-12-25",  # Christmas
    "2025-01-01",  # New Year's Day
    "2025-01-20",  # Martin Luther King Jr. Day
    "2025-02-17",  # Presidents Day
    "2025-04-18",  # Good Friday
    "2025-05-26",  # Memorial Day
    "2025-06-19",  # Juneteenth
    "2025-07-04",  # Independence Day
    "2025-09-01",  # Labor Day
    "2025-11-27",  # Thanksgiving
    "2025-12-25",  # Christmas
]

def get_california_time():
    """ìº˜ë¦¬í¬ë‹ˆì•„ ì‹œê°„ëŒ€ í˜„ì¬ ì‹œê°„"""
    pacific = pytz.timezone('America/Los_Angeles')
    return datetime.now(pacific)

def is_market_open():
    """ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ì´ í˜„ì¬ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸"""
    now = get_california_time()
    
    # ì£¼ë§ ì²´í¬ (í† ìš”ì¼=5, ì¼ìš”ì¼=6)
    if now.weekday() >= 5:
        return False
    
    # ê³µíœ´ì¼ ì²´í¬
    if now.strftime("%Y-%m-%d") in US_MARKET_HOLIDAYS:
        return False
    
    # ì‹œì¥ ì‹œê°„ ì²´í¬ (ìº˜ë¦¬í¬ë‹ˆì•„ ì‹œê°„ ê¸°ì¤€: 06:30 - 13:00)
    market_open_time = now.replace(hour=6, minute=30, second=0, microsecond=0)
    market_close_time = now.replace(hour=13, minute=0, second=0, microsecond=0)
    
    return market_open_time <= now <= market_close_time

def get_last_trading_day():
    """ì§ì „ ê±°ë˜ì¼ ì°¾ê¸°"""
    now = get_california_time()
    current_date = now.date()
    
    # ìµœëŒ€ 10ì¼ ì „ê¹Œì§€ í™•ì¸
    for i in range(1, 11):
        check_date = current_date - timedelta(days=i)
        
        # ì£¼ë§ì´ ì•„ë‹ˆê³ 
        if check_date.weekday() < 5:
            # ê³µíœ´ì¼ì´ ì•„ë‹ˆë©´
            if check_date.strftime("%Y-%m-%d") not in US_MARKET_HOLIDAYS:
                return check_date
    
    # ëª» ì°¾ìœ¼ë©´ ê·¸ëƒ¥ ì „ë‚ 
    return current_date - timedelta(days=1)

def get_market_status():
    """ì‹œì¥ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
    is_open = is_market_open()
    now = get_california_time()
    
    if is_open:
        return {
            "is_open": True,
            "date": now.strftime("%Y-%m-%d"),
            "message": "ì‹œì¥ ê°œì¥ ì¤‘",
            "california_time": now.strftime("%Y-%m-%d %H:%M:%S %Z")
        }
    else:
        last_trading = get_last_trading_day()
        
        # ì£¼ë§ì¸ì§€ ê³µíœ´ì¼ì¸ì§€ í™•ì¸
        if now.weekday() >= 5:
            reason = "ì£¼ë§"
        elif now.strftime("%Y-%m-%d") in US_MARKET_HOLIDAYS:
            reason = "ê³µíœ´ì¼"
        else:
            reason = "ì‹œì¥ ë§ˆê°"
        
        return {
            "is_open": False,
            "date": last_trading.strftime("%Y-%m-%d"),
            "message": f"{reason} - ì§ì „ ê±°ë˜ì¼ ({last_trading.strftime('%Y-%m-%d')}) ë°ì´í„° í‘œì‹œ",
            "california_time": now.strftime("%Y-%m-%d %H:%M:%S %Z")
        }

class Stock52Week(BaseModel):
    symbol: str
    name: str
    price: float
    high_52week: Optional[float] = None
    low_52week: Optional[float] = None
    change: float
    change_percent: float
    days_at_high: Optional[int] = None
    days_at_low: Optional[int] = None
    sector: str
    market_cap: float
    volume: float
    market_cap_category: Optional[str] = None

class MarketCapStats(BaseModel):
    category: str
    highs_count: int
    lows_count: int
    ratio: float
    total_stocks: int

# ìºì‹œ ì €ì¥ì†Œ
_cache: Dict[str, any] = {
    "data": [],
    "last_update": None,
    "updating": False
}

def get_sp500_tickers() -> List[str]:
    """S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    try:
        import requests
        headers = {'User-Agent': 'Mozilla/5.0'}
        url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
        response = requests.get(url, headers=headers, timeout=10)
        table = pd.read_html(response.content)
        df = table[0]
        return df['Symbol'].str.replace('.', '-').tolist()
    except Exception as e:
        print(f"S&P 500 í‹°ì»¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        # Fallback: ì£¼ìš” ì¢…ëª© í•˜ë“œì½”ë”©
        return [
            "AAPL", "MSFT", "GOOGL", "GOOG", "AMZN", "NVDA", "META", "TSLA", "BRK-B", "UNH",
            "XOM", "V", "JPM", "JNJ", "WMT", "MA", "PG", "AVGO", "HD", "CVX",
            "LLY", "ABBV", "MRK", "KO", "PEP", "COST", "ADBE", "BAC", "TMO", "MCD",
        ]

def get_nasdaq100_tickers() -> List[str]:
    """NASDAQ 100 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    try:
        import requests
        headers = {'User-Agent': 'Mozilla/5.0'}
        url = 'https://en.wikipedia.org/wiki/NASDAQ-100'
        response = requests.get(url, headers=headers, timeout=10)
        table = pd.read_html(response.content)
        df = table[4]
        return df['Ticker'].str.replace('.', '-').tolist()
    except Exception as e:
        print(f"NASDAQ 100 í‹°ì»¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        # Fallback: ì£¼ìš” ì¢…ëª© í•˜ë“œì½”ë”©
        return [
            "AAPL", "MSFT", "GOOGL", "GOOG", "AMZN", "NVDA", "META", "TSLA", "AVGO", "NFLX",
            "AMD", "INTC", "CSCO", "ADBE", "PEP", "COST", "CMCSA", "QCOM", "TXN", "AMGN",
        ]

def get_all_tickers() -> List[str]:
    """S&P 500 + NASDAQ 100 ì¢…ëª© (ì¤‘ë³µ ì œê±°)"""
    try:
        sp500 = get_sp500_tickers()
        nasdaq100 = get_nasdaq100_tickers()
        
        # ì¶”ê°€ ì£¼ìš” ì¢…ëª© (Russell 2000, Dow Jones ë“±ì—ì„œ ì„ ë³„)
        additional = [
            "CRM", "ORCL", "ACN", "NOW", "IBM", "INTU", "AMAT", "MU", "ADI", "KLAC",
            "NFLX", "DIS", "CMCSA", "VZ", "T", "TMUS", "CHTR",
            "WFC", "C", "GS", "MS", "SCHW", "AXP", "BLK", "SPGI",
            "NKE", "SBUX", "MCD", "TJX", "LOW", "HD", "TGT", "BKNG",
            "UNP", "UPS", "FDX", "LMT", "RTX", "BA", "CAT", "DE",
            "ABT", "PFE", "BMY", "GILD", "MRNA", "REGN", "VRTX", "ISRG",
            "NEE", "DUK", "SO", "AEP", "EXC", "SRE", "D", "PEG",
            "PLD", "AMT", "CCI", "EQIX", "PSA", "SPG", "O", "WELL"
        ]
        
        all_tickers = list(set(sp500 + nasdaq100 + additional))
        print(f"âœ… ì´ {len(all_tickers)}ê°œ ì¢…ëª© ë¡œë“œ (S&P 500: {len(sp500)}, NASDAQ 100: {len(nasdaq100)}, ì¶”ê°€: {len(additional)})")
        return all_tickers
    except Exception as e:
        print(f"í‹°ì»¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []

def categorize_market_cap(market_cap_billions: float) -> str:
    """ì‹œì´ ê¸°ì¤€ ë¶„ë¥˜ (ë‹¨ìœ„: ì‹­ì–µ ë‹¬ëŸ¬)"""
    market_cap = market_cap_billions * 1000  # ì¡° -> ì‹­ì–µ ë‹¬ëŸ¬
    if market_cap >= 200:
        return "ëŒ€í˜•ì£¼ (Mega Cap)"
    elif market_cap >= 10:
        return "ëŒ€í˜•ì£¼ (Large Cap)"
    elif market_cap >= 2:
        return "ì¤‘í˜•ì£¼ (Mid Cap)"
    else:
        return "ì†Œí˜•ì£¼ (Small Cap)"

def get_stock_data(symbol: str) -> Optional[dict]:
    """ê°œë³„ ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    try:
        ticker = yf.Ticker(symbol)
        info = ticker.info
        hist = ticker.history(period="1y")
        
        if hist.empty:
            return None
        
        # í˜„ì¬ ê°€ê²© ê°€ì ¸ì˜¤ê¸°
        current_price = info.get("currentPrice") or info.get("regularMarketPrice")
        if not current_price or current_price <= 0:
            current_price = hist["Close"].iloc[-1] if not hist.empty else None
        
        if not current_price:
            return None
        
        high_52week = info.get("fiftyTwoWeekHigh", hist["High"].max())
        low_52week = info.get("fiftyTwoWeekLow", hist["Low"].min())
        
        # 52ì£¼ ì‹ ê³ ê°€/ì‹ ì €ê°€ ê·¼ì ‘ë„ ê³„ì‚° (3% ì´ë‚´)
        near_high = (current_price >= high_52week * 0.97)
        near_low = (current_price <= low_52week * 1.03)
        
        # ì‹¤ì œ ë³€ë™ë¥  ì‚¬ìš© (yfinanceì—ì„œ ì§ì ‘ ì œê³µ)
        change = info.get("regularMarketChange")
        change_percent = info.get("regularMarketChangePercent")
        
        # fallback: ê³„ì‚°ëœ ë³€ë™ë¥ 
        if change is None or change_percent is None or pd.isna(change) or pd.isna(change_percent):
            # previousClose ì‚¬ìš© (ë” ì‹ ë¢°ì„± ìˆìŒ)
            prev_close = info.get("previousClose") or info.get("regularMarketPreviousClose")
            
            if prev_close and prev_close > 0:
                change = current_price - prev_close
                change_percent = (change / prev_close * 100)
            elif len(hist) > 1:
                # íˆìŠ¤í† ë¦¬ì—ì„œ ì „ì¼ ì¢…ê°€ ê°€ì ¸ì˜¤ê¸°
                prev_close = hist["Close"].iloc[-2]
                if not pd.isna(prev_close) and prev_close > 0:
                    change = current_price - prev_close
                    change_percent = (change / prev_close * 100)
                else:
                    change = 0
                    change_percent = 0
            else:
                change = 0
                change_percent = 0
        
        # NaN ì²´í¬ ë° ê¸°ë³¸ê°’ ì„¤ì •
        if pd.isna(change):
            change = 0
        if pd.isna(change_percent):
            change_percent = 0
        
        market_cap_billions = round(info.get("marketCap", 0) / 1e12, 2)  # ì¡° ë‹¬ëŸ¬
        market_cap_category = categorize_market_cap(market_cap_billions)
        
        return {
            "symbol": symbol,
            "name": info.get("longName", symbol),
            "price": round(current_price, 2),
            "high_52week": round(high_52week, 2),
            "low_52week": round(low_52week, 2),
            "change": round(change, 2),
            "change_percent": round(change_percent, 2),
            "days_at_high": 1 if near_high else None,
            "days_at_low": 1 if near_low else None,
            "sector": info.get("sector", "Unknown"),
            "market_cap": market_cap_billions,
            "volume": round(info.get("volume", 0) / 1e6, 1),  # ë°±ë§Œ
            "market_cap_category": market_cap_category,
            "is_near_high": near_high,
            "is_near_low": near_low
        }
    except Exception as e:
        print(f"Error fetching {symbol}: {e}")
        return None

def fetch_all_stocks_data() -> List[dict]:
    """ëª¨ë“  ì¢…ëª© ë°ì´í„°ë¥¼ ë³‘ë ¬ë¡œ ê°€ì ¸ì˜¤ê¸°"""
    tickers = get_all_tickers()
    all_data = []
    
    print(f"ğŸ“Š {len(tickers)}ê°œ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    start_time = time.time()
    
    # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ
    with ThreadPoolExecutor(max_workers=10) as executor:
        future_to_symbol = {executor.submit(get_stock_data, symbol): symbol for symbol in tickers}
        
        for future in as_completed(future_to_symbol):
            try:
                data = future.result()
                if data:
                    all_data.append(data)
            except Exception as e:
                symbol = future_to_symbol[future]
                print(f"âŒ {symbol} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    elapsed = time.time() - start_time
    print(f"âœ… {len(all_data)}ê°œ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ({elapsed:.1f}ì´ˆ)")
    
    return all_data

def update_cache():
    """ìºì‹œ ì—…ë°ì´íŠ¸ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)"""
    global _cache
    
    if _cache["updating"]:
        print("â³ ì´ë¯¸ ì—…ë°ì´íŠ¸ ì¤‘ì…ë‹ˆë‹¤.")
        return
    
    _cache["updating"] = True
    try:
        data = fetch_all_stocks_data()
        _cache["data"] = data
        _cache["last_update"] = datetime.now()
        print(f"âœ… ìºì‹œ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(data)}ê°œ ì¢…ëª©")
    except Exception as e:
        print(f"âŒ ìºì‹œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    finally:
        _cache["updating"] = False

def get_cached_data() -> List[dict]:
    """ìºì‹œëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (15ë¶„ë§ˆë‹¤ ìë™ ê°±ì‹ )"""
    global _cache
    
    # ìºì‹œê°€ ë¹„ì–´ìˆê±°ë‚˜ 15ë¶„ì´ ì§€ë‚¬ìœ¼ë©´ ì—…ë°ì´íŠ¸
    if not _cache["data"] or not _cache["last_update"] or \
       (datetime.now() - _cache["last_update"]) > timedelta(minutes=15):
        if not _cache["updating"]:
            print("ğŸ”„ ìºì‹œ ë§Œë£Œ, ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì—…ë°ì´íŠ¸ ì‹œì‘...")
            from threading import Thread
            Thread(target=update_cache, daemon=True).start()
    
    return _cache["data"]

@router.get("/highs")
async def get_52week_highs(
    limit: int = Query(20, ge=1, le=100),
    market_cap: Optional[str] = Query(None, description="ëŒ€í˜•ì£¼, ì¤‘í˜•ì£¼, ì†Œí˜•ì£¼")
):
    """
    52ì£¼ ì‹ ê³ ê°€ ì¢…ëª© ì¡°íšŒ
    
    ë°ì´í„° ì†ŒìŠ¤:
    - S&P 500: ë¯¸êµ­ ëŒ€í˜•ì£¼ 500ê°œ (Wikipedia API)
    - NASDAQ 100: ë‚˜ìŠ¤ë‹¥ ìƒì¥ ëŒ€í˜• ê¸°ìˆ ì£¼ 100ê°œ (Wikipedia API)
    - ì¶”ê°€ ì£¼ìš” ì¢…ëª©: Russell, Dow Jones ë“±ì—ì„œ ì„ ë³„í•œ 60ê°œ
    - ì´ ë¶„ì„ ëŒ€ìƒ: ì•½ 600ê°œ ì¢…ëª© (ì¤‘ë³µ ì œê±° í›„ ì‹¤ì œ ìˆ˜ì§‘: ~200ê°œ)
    
    ì—…ë°ì´íŠ¸ ì£¼ê¸°:
    - ìë™ ê°±ì‹ : 15ë¶„ë§ˆë‹¤
    - ìˆ˜ë™ ê°±ì‹ : POST /api/52week/refresh
    
    Parameters:
    - limit: ë°˜í™˜í•  ì¢…ëª© ìˆ˜ (ê¸°ë³¸ 20, ìµœëŒ€ 100)
    - market_cap: ì‹œì´ í•„í„° (Mega, Large, Mid, Small)
    """
    all_data = get_cached_data()
    
    # ì‹ ê³ ê°€ ì¢…ëª© í•„í„°ë§
    highs = [stock for stock in all_data if stock.get("is_near_high")]
    
    # ì‹œì´ í•„í„°ë§
    if market_cap:
        highs = [stock for stock in highs if market_cap in stock.get("market_cap_category", "")]
    
    # ì‹œì´ ìˆœìœ¼ë¡œ ì •ë ¬
    highs.sort(key=lambda x: x.get("market_cap", 0), reverse=True)
    
    return {
        "stocks": highs[:limit],
        "total": len(highs)
    }

@router.get("/lows")
async def get_52week_lows(
    limit: int = Query(20, ge=1, le=100),
    market_cap: Optional[str] = Query(None, description="ëŒ€í˜•ì£¼, ì¤‘í˜•ì£¼, ì†Œí˜•ì£¼")
):
    """
    52ì£¼ ì‹ ì €ê°€ ì¢…ëª© ì¡°íšŒ
    
    ë°ì´í„° ì†ŒìŠ¤:
    - S&P 500 + NASDAQ 100 + ì¶”ê°€ ì£¼ìš” ì¢…ëª©
    - ì´ ë¶„ì„ ëŒ€ìƒ: ì•½ 600ê°œ ì¢…ëª©
    
    Parameters:
    - limit: ë°˜í™˜í•  ì¢…ëª© ìˆ˜
    - market_cap: ì‹œì´ í•„í„°
    """
    all_data = get_cached_data()
    
    # ì‹ ì €ê°€ ì¢…ëª© í•„í„°ë§
    lows = [stock for stock in all_data if stock.get("is_near_low")]
    
    # ì‹œì´ í•„í„°ë§
    if market_cap:
        lows = [stock for stock in lows if market_cap in stock.get("market_cap_category", "")]
    
    # ì‹œì´ ìˆœìœ¼ë¡œ ì •ë ¬
    lows.sort(key=lambda x: x.get("market_cap", 0), reverse=True)
    
    return {
        "stocks": lows[:limit],
        "total": len(lows)
    }

@router.get("/stats")
async def get_52week_stats():
    """52ì£¼ ì‹ ê³ ê°€/ì‹ ì €ê°€ ì „ì²´ í†µê³„"""
    all_data = get_cached_data()
    market_status = get_market_status()
    
    highs = [s for s in all_data if s.get("is_near_high")]
    lows = [s for s in all_data if s.get("is_near_low")]
    
    highs_count = len(highs)
    lows_count = len(lows)
    ratio = round(highs_count / lows_count, 2) if lows_count > 0 else 0
    
    # ì‹œì¥ ê°•ë„ íŒë‹¨
    if ratio > 2.5:
        market_breadth = "strong"
    elif ratio > 1.5:
        market_breadth = "positive"
    elif ratio > 0.7:
        market_breadth = "neutral"
    else:
        market_breadth = "weak"
    
    return {
        "highs_count": highs_count,
        "lows_count": lows_count,
        "ratio": ratio,
        "market_breadth": market_breadth,
        "total_stocks": len(all_data),
        "last_update": _cache["last_update"].isoformat() if _cache["last_update"] else None,
        "market_status": market_status
    }

@router.get("/stats/by-market-cap", response_model=List[MarketCapStats])
async def get_52week_stats_by_market_cap():
    """ì‹œì´ë³„ 52ì£¼ ì‹ ê³ ê°€/ì‹ ì €ê°€ í†µê³„"""
    all_data = get_cached_data()
    
    categories = {}
    
    for stock in all_data:
        cat = stock.get("market_cap_category", "Unknown")
        if cat not in categories:
            categories[cat] = {"total": 0, "highs": 0, "lows": 0}
        
        categories[cat]["total"] += 1
        if stock.get("is_near_high"):
            categories[cat]["highs"] += 1
        if stock.get("is_near_low"):
            categories[cat]["lows"] += 1
    
    result = []
    for cat, data in categories.items():
        ratio = round(data["highs"] / data["lows"], 2) if data["lows"] > 0 else 0
        result.append({
            "category": cat,
            "highs_count": data["highs"],
            "lows_count": data["lows"],
            "ratio": ratio,
            "total_stocks": data["total"]
        })
    
    # ì‹œì´ ìˆœì„œë¡œ ì •ë ¬
    order = ["ëŒ€í˜•ì£¼ (Mega Cap)", "ëŒ€í˜•ì£¼ (Large Cap)", "ì¤‘í˜•ì£¼ (Mid Cap)", "ì†Œí˜•ì£¼ (Small Cap)"]
    result.sort(key=lambda x: order.index(x["category"]) if x["category"] in order else 999)
    
    return result

@router.get("/history")
async def get_52week_history(days: int = Query(30, ge=1, le=365)):
    """
    52ì£¼ ì‹ ê³ ê°€/ì‹ ì €ê°€ ì¶”ì´ (íˆìŠ¤í† ë¦¬)
    
    ìµœê·¼ Nì¼ê°„ì˜ ì‹ ê³ ê°€/ì‹ ì €ê°€ ì¢…ëª© ìˆ˜ ì¶”ì´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì‹¤ì œë¡œëŠ” yfinanceì—ì„œ ê³¼ê±° ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Parameters:
    - days: ì¡°íšŒí•  ì¼ìˆ˜ (ê¸°ë³¸ 30ì¼, ìµœëŒ€ 365ì¼)
    
    Returns:
    - date: ë‚ ì§œ
    - highs_count: í•´ë‹¹ì¼ ì‹ ê³ ê°€ ì¢…ëª© ìˆ˜
    - lows_count: í•´ë‹¹ì¼ ì‹ ì €ê°€ ì¢…ëª© ìˆ˜
    - ratio: ì‹ ê³ ê°€/ì‹ ì €ê°€ ë¹„ìœ¨
    - market_breadth: ì‹œì¥ ê°•ë„
    """
    # ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜: ìµœê·¼ 30ì¼ê°„ ë°ì´í„°
    # ì‹¤ì œë¡œëŠ” ë§¤ì¼ ìºì‹œë¥¼ ì €ì¥í•˜ê±°ë‚˜ yfinanceë¡œ ê³¼ê±° ë°ì´í„° ê³„ì‚°
    from datetime import timedelta
    
    history = []
    current_data = get_cached_data()
    
    # í˜„ì¬ ë°ì´í„°ë¡œë¶€í„° ì¶”ì • (ì‹¤ì œë¡œëŠ” DBì— ì €ì¥ëœ ê³¼ê±° ë°ì´í„° ì‚¬ìš©)
    base_date = datetime.now()
    
    for i in range(min(days, 30)):
        date = base_date - timedelta(days=i)
        
        # ê°„ë‹¨í•œ ì¶”ì •: ì‹¤ì œë¡œëŠ” ê³¼ê±° ë°ì´í„°ë¥¼ ê³„ì‚°í•´ì•¼ í•¨
        # í˜„ì¬ëŠ” í˜„ì¬ ë°ì´í„°ì— ì•½ê°„ì˜ ë³€ë™ì„ ì£¼ì–´ ì‹œë®¬ë ˆì´ì…˜
        import random
        variation = random.uniform(0.8, 1.2)
        
        highs = int(len([s for s in current_data if s.get("is_near_high")]) * variation)
        lows = int(len([s for s in current_data if s.get("is_near_low")]) * variation)
        ratio = round(highs / lows, 2) if lows > 0 else 0
        
        if ratio > 2.5:
            breadth = "strong"
        elif ratio > 1.5:
            breadth = "positive"
        elif ratio > 0.7:
            breadth = "neutral"
        else:
            breadth = "weak"
        
        history.append({
            "date": date.strftime("%Y-%m-%d"),
            "highs_count": highs,
            "lows_count": lows,
            "ratio": ratio,
            "market_breadth": breadth
        })
    
    # ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
    history.reverse()
    
    return {
        "history": history,
        "days": len(history),
        "note": "í˜„ì¬ëŠ” ì¶”ì • ë°ì´í„°ì…ë‹ˆë‹¤. ì‹¤ì œ íˆìŠ¤í† ë¦¬ ì¶”ì ì„ ìœ„í•´ì„œëŠ” ë§¤ì¼ ë°ì´í„°ë¥¼ DBì— ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤."
    }

@router.get("/advance-decline")
async def get_advance_decline():
    """
    ì‹œì¥ ë“±ë½ ì¢…ëª© ìˆ˜ (Advance/Decline)
    
    í˜„ì¬ ì‹œì¥ì—ì„œ:
    - ìƒìŠ¹ ì¢…ëª© ìˆ˜
    - í•˜ë½ ì¢…ëª© ìˆ˜
    - ë³´í•© ì¢…ëª© ìˆ˜
    - A/D Line (ëˆ„ì )
    
    ì´ëŠ” 52ì£¼ ì‹ ê³ ê°€/ì‹ ì €ê°€ì™€ëŠ” ë‹¤ë¥¸ ê°œë…ìœ¼ë¡œ,
    ë‹¹ì¼ ê°€ê²© ë³€ë™ì„ ê¸°ì¤€ìœ¼ë¡œ í•©ë‹ˆë‹¤.
    """
    all_data = get_cached_data()
    market_status = get_market_status()
    
    advancing = len([s for s in all_data if s.get("change_percent", 0) > 0])
    declining = len([s for s in all_data if s.get("change_percent", 0) < 0])
    unchanged = len([s for s in all_data if s.get("change_percent", 0) == 0])
    
    # A/D Ratio
    ad_ratio = round(advancing / declining, 2) if declining > 0 else 0
    
    # ì‹œì¥ ìƒíƒœ íŒë‹¨
    if ad_ratio > 2:
        market_sentiment = "ë§¤ìš° ê°•ì„¸"
    elif ad_ratio > 1.5:
        market_sentiment = "ê°•ì„¸"
    elif ad_ratio > 1:
        market_sentiment = "ì•½í•œ ê°•ì„¸"
    elif ad_ratio > 0.67:
        market_sentiment = "ì•½í•œ ì•½ì„¸"
    elif ad_ratio > 0.5:
        market_sentiment = "ì•½ì„¸"
    else:
        market_sentiment = "ë§¤ìš° ì•½ì„¸"
    
    return {
        "advancing": advancing,
        "declining": declining,
        "unchanged": unchanged,
        "total_stocks": len(all_data),
        "ad_ratio": ad_ratio,
        "market_sentiment": market_sentiment,
        "timestamp": get_california_time().isoformat(),
        "note": f"ì´ {len(all_data)}ê°œ ì¢…ëª© ì¤‘ ìƒìŠ¹ {advancing}ê°œ, í•˜ë½ {declining}ê°œ",
        "market_status": market_status
    }

@router.get("/market-status")
async def get_market_status_endpoint():
    """
    ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ ê°œì¥ ì—¬ë¶€ í™•ì¸
    
    ìº˜ë¦¬í¬ë‹ˆì•„ ì‹œê°„ëŒ€ ê¸°ì¤€ìœ¼ë¡œ:
    - ì£¼ë§ ì—¬ë¶€ ì²´í¬
    - ê³µíœ´ì¼ ì—¬ë¶€ ì²´í¬
    - ì‹œì¥ ì‹œê°„(06:30-13:00 PST) ì²´í¬
    - ì§ì „ ê±°ë˜ì¼ ê³„ì‚°
    
    Returns:
    - is_open: ì‹œì¥ ê°œì¥ ì—¬ë¶€
    - date: í˜„ì¬ ë‚ ì§œ (ë˜ëŠ” ì§ì „ ê±°ë˜ì¼)
    - message: ìƒíƒœ ë©”ì‹œì§€
    - california_time: ìº˜ë¦¬í¬ë‹ˆì•„ í˜„ì¬ ì‹œê°„
    """
    return get_market_status()

@router.post("/refresh")
async def refresh_cache():
    """
    ìºì‹œ ê°•ì œ ìƒˆë¡œê³ ì¹¨
    
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ S&P 500 + NASDAQ 100 + ì¶”ê°€ ì¢…ëª© ë°ì´í„°ë¥¼ ë‹¤ì‹œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    ìˆ˜ì§‘ ì‹œê°„: ì•½ 30ì´ˆ ~ 1ë¶„ (ë„¤íŠ¸ì›Œí¬ ìƒíƒœì— ë”°ë¼ ë‹¤ë¦„)
    """
    from threading import Thread
    Thread(target=update_cache, daemon=True).start()
    return {
        "message": "ìºì‹œ ì—…ë°ì´íŠ¸ ì‹œì‘",
        "status": "updating",
        "estimated_time": "30-60ì´ˆ",
        "target_stocks": "S&P 500 + NASDAQ 100 + ì¶”ê°€ ì£¼ìš” ì¢…ëª©"
    }

